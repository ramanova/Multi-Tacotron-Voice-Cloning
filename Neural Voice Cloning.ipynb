{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yk3PMfBuZhS"
   },
   "source": [
    "Make sure GPU is enabled\n",
    "Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOiGYfpAf2qR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:91: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n",
      "Arguments:\n",
      "    enc_model_fpath:   encoder/saved_models/pretrained.pt\n",
      "    syn_model_dir:     synthesizer/saved_models/logs_pretrained\n",
      "    voc_model_fpath:   vocoder/saved_models/pretrained/pretrained.pt\n",
      "    low_mem:           False\n",
      "    no_sound:          True\n",
      "    text:              Hello my friends. Я многоязычный синтез построенный на tacotron. Шла саша по шоссе и сосала сушку\n",
      "    path_wav:          ex.wav\n",
      "\n",
      "Running a test of your configuration...\n",
      "\n",
      "Found 1 GPUs available. Using GPU 0 (Tesla M60) of compute capability 5.2 with 8.0Gb total memory.\n",
      "\n",
      "Preparing the encoder, the synthesizer and the vocoder...\n",
      "Loaded encoder \"pretrained.pt\" trained to step 1617001\n",
      "Found synthesizer \"logs_pretrained\" trained to step 348000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at vocoder/saved_models/pretrained/pretrained.pt\n",
      "Testing your configuration with small inputs.\n",
      "\tTesting the encoder...\n",
      "\tTesting the synthesizer... (loading the model will output a lot of text)\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/inference.py:59: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Constructing model: Tacotron\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/tacotron2.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/tacotron2.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/tacotron.py:86: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/tacotron.py:123: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/tacotron.py:135: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:112: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:421: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:422: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:425: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:156: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/attention.py:158: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/attention.py:161: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:305: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/modules.py:269: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f0c58210630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f0c58210630>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f0c58210630>>, which Python reported as:\n",
      "    def __call__(self, inputs, state, scope=None):\n",
      "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
      "        \"\"\"\n",
      "        # Apply vanilla LSTM\n",
      "        output, new_state = self._cell(inputs, state, scope)\n",
      "\n",
      "        if self.state_is_tuple:\n",
      "            (prev_c, prev_h) = state\n",
      "            (new_c, new_h) = new_state\n",
      "        else:\n",
      "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\n",
      "\t\t\t\tself._cell._num_proj\n",
      "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
      "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
      "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
      "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
      "\n",
      "        # Apply zoneout\n",
      "        if self.is_training:\n",
      "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\n",
      "\t\t\t# probability to mask activations)!\n",
      "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
      "                                                         (1 - self._zoneout_cell)) + prev_c\n",
      "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
      "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
      "\n",
      "        else:\n",
      "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
      "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
      "\n",
      "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
      "                                                                                                  h])\n",
      "\n",
      "        return output, new_state\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f0c53f09198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f0c53f09198>>: ValueError: Failed to parse source code of <bound method ZoneoutLSTMCell.__call__ of <synthesizer.models.modules.ZoneoutLSTMCell object at 0x7f0c53f09198>>, which Python reported as:\n",
      "    def __call__(self, inputs, state, scope=None):\n",
      "        \"\"\"Runs vanilla LSTM Cell and applies zoneout.\n",
      "        \"\"\"\n",
      "        # Apply vanilla LSTM\n",
      "        output, new_state = self._cell(inputs, state, scope)\n",
      "\n",
      "        if self.state_is_tuple:\n",
      "            (prev_c, prev_h) = state\n",
      "            (new_c, new_h) = new_state\n",
      "        else:\n",
      "            num_proj = self._cell._num_units if self._cell._num_proj is None else \\\n",
      "\t\t\t\tself._cell._num_proj\n",
      "            prev_c = tf.slice(state, [0, 0], [-1, self._cell._num_units])\n",
      "            prev_h = tf.slice(state, [0, self._cell._num_units], [-1, num_proj])\n",
      "            new_c = tf.slice(new_state, [0, 0], [-1, self._cell._num_units])\n",
      "            new_h = tf.slice(new_state, [0, self._cell._num_units], [-1, num_proj])\n",
      "\n",
      "        # Apply zoneout\n",
      "        if self.is_training:\n",
      "            # nn.dropout takes keep_prob (probability to keep activations) not drop_prob (\n",
      "\t\t\t# probability to mask activations)!\n",
      "            c = (1 - self._zoneout_cell) * tf.nn.dropout(new_c - prev_c,\n",
      "                                                         (1 - self._zoneout_cell)) + prev_c\n",
      "            h = (1 - self._zoneout_outputs) * tf.nn.dropout(new_h - prev_h,\n",
      "                                                            (1 - self._zoneout_outputs)) + prev_h\n",
      "\n",
      "        else:\n",
      "            c = (1 - self._zoneout_cell) * new_c + self._zoneout_cell * prev_c\n",
      "            h = (1 - self._zoneout_outputs) * new_h + self._zoneout_outputs * prev_h\n",
      "\n",
      "        new_state = tf.nn.rnn_cell.LSTMStateTuple(c, h) if self.state_is_tuple else tf.concat(1, [c,\n",
      "                                                                                                  h])\n",
      "\n",
      "        return output, new_state\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "initialisation done /gpu:0\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/models/tacotron.py:286: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
      "  Train mode:               False\n",
      "  Eval mode:                False\n",
      "  GTA mode:                 False\n",
      "  Synthesis mode:           True\n",
      "  Input:                    (?, ?)\n",
      "  device:                   0\n",
      "  embedding:                (?, ?, 512)\n",
      "  enc conv out:             (?, ?, 512)\n",
      "  encoder out (cond):       (?, ?, 768)\n",
      "  decoder out:              (?, ?, 80)\n",
      "  residual out:             (?, ?, 512)\n",
      "  projected residual out:   (?, ?, 80)\n",
      "  mel out:                  (?, ?, 80)\n",
      "  <stop_token> out:         (?, ?)\n",
      "  Tacotron Parameters       28.618 Million.\n",
      "Loading checkpoint: synthesizer/saved_models/logs_pretrained/taco_pretrained/tacotron_model.ckpt-348000\n",
      "2020-07-22 19:49:35.291922: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-07-22 19:49:35.297487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-22 19:49:35.297980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:35.298634: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557f573d84d0 executing computations on platform CUDA. Devices:\n",
      "2020-07-22 19:49:35.298662: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-22 19:49:35.320192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300065000 Hz\n",
      "2020-07-22 19:49:35.320451: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557f571a40f0 executing computations on platform Host. Devices:\n",
      "2020-07-22 19:49:35.320486: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-07-22 19:49:35.320671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:35.321205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775\n",
      "pciBusID: 0000:00:1e.0\n",
      "2020-07-22 19:49:35.321491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-07-22 19:49:35.322681: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-07-22 19:49:35.323868: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-07-22 19:49:35.324224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-07-22 19:49:35.325631: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-07-22 19:49:35.326687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-07-22 19:49:35.329895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-22 19:49:35.330013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:35.330601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:35.331116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-07-22 19:49:35.331181: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-07-22 19:49:35.332809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-22 19:49:35.332838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-07-22 19:49:35.332863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-07-22 19:49:35.333004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:35.333583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:35.334112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6095 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)\n",
      "2020-07-22 19:49:35.519360: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/synthesizer/tacotron2.py:62: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-07-22 19:49:36.808562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-07-22 19:49:37.020682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "\tTesting the vocoder...\n",
      "All test passed! You can now synthesize speech.\n",
      "\n",
      "\n",
      "This is a GUI-less example of interface to SV2TTS. The purpose of this script is to show how you can interface this project easily with your own. See the source code for an explanation of what is happening.\n",
      "\n",
      "Interactive generation loop\n",
      "file location:  /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning\n",
      "Loaded file succesfully\n",
      "Created the embedding\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/g2p/train.py:321: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/g2p/train.py:321: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/g2p/train.py:321: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/g2p/train.py:151: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/vlomme2/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Inference graph is being built. Please be patient.\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]WARNING:tensorflow:From /home/ubuntu/ainovia/vlomme_cloning/Multi-Tacotron-Voice-Cloning/g2p/train.py:183: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:02<00:00,  7.85it/s]\n",
      "2020-07-22 19:49:42.504900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:42.505453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775\n",
      "pciBusID: 0000:00:1e.0\n",
      "2020-07-22 19:49:42.505568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-07-22 19:49:42.505618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-07-22 19:49:42.505658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-07-22 19:49:42.505698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-07-22 19:49:42.505742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-07-22 19:49:42.505808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-07-22 19:49:42.505866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-22 19:49:42.505954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:42.506524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:42.507011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-07-22 19:49:42.507057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-22 19:49:42.507082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-07-22 19:49:42.507103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-07-22 19:49:42.507238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:42.507792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-22 19:49:42.508306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6095 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)\n",
      "0 / 1\n",
      "0\n",
      "[' hEлоу мАй фрEндз. йА мнагайизЫчный СИнцы пасTрОйиный нА тЭкaтрАн. шлА сАша пО шОСи и сасАла сушкУ']\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "{| ████████████████ 95000/96000 | Batch Size: 10 | Gen Rate: 10.2kHz | }float64\n",
      "\n",
      "Saved output as demo_output_22_07_19_49_0.wav\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python demo_cli.py -p \"ex.wav\" -t \"Hello my friends. Я многоязычный синтез построенный на tacotron. Шла саша по шоссе и сосала сушку\" --no_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyLdbUfks2lv"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "print(\"original(оригинал)\")\n",
    "ipd.display(ipd.Audio('ex.wav'))#filepath to original voices (Путь до оригинального файла)\n",
    "print(\"cloned(клонированный)\")\n",
    "ipd.display(ipd.Audio('demo_output_00.wav'))#filepath to synthesized voices (Путь до синтезированного файла)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multi-Tacotron-Voice-Cloning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
